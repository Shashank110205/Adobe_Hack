# ğŸ§¾ PDF Heading Extractor

This project extracts structured outlines from PDF documents by detecting headings and classifying them into hierarchical levels (H1, H2, H3). The solution is designed to be efficient, multilingual-aware, and ready for scaling across diverse document types.

---
## Team
Name : InnovationNation 

Members : 
- [Shashank Tiwari](https://github.com/Shashank110205)
- [Badal Singh](https://github.com/Badalsingh2)
- [Vivian Ludrick](https://github.com/vivalchemy)

---

## ğŸ” What This Project Does

This tool:

* Scans PDFs for structural headings like titles and section headers
* Detects the language of each heading
* Translates non-English headings into English
* Embeds the translated headings using a fast ONNX model
* Predicts their structure level using a trained machine learning classifier
* Outputs a clean, structured JSON outline for each PDF

---

## Model Used:
**all-MiniLM-L6-v2** *(87MiB)*

---

## âœ… Key Features

| Feature                    | Description                                                                   |
| -------------------------- | ----------------------------------------------------------------------------- |
| ğŸŒ Multilingual Support    | Automatically detects and translates non-English headings                     |
| âš¡ Optimized Inference      | Uses ONNX and batch processing for faster embedding                           |
| ğŸ§  Accurate Classification | Predicts heading levels (H1, H2, H3) with a trained Logistic Regression model |
| ğŸ§¹ Noise Removal           | Filters out non-structural text (e.g., page numbers, footers)                 |
| ğŸ” Duplicate Detection     | Skips repeated headings to avoid clutter                                      |
| ğŸ§¾ Logging                 | Keeps logs of all removed and duplicate entries                               |
| ğŸš€ Scalable                | Supports concurrent processing of multiple PDFs                               |

---

## ğŸ“ Project Structure

```
ğŸ“¦ Project Root
â”œâ”€â”€ ğŸ“‚ input/                # Drop your PDFs here
â”œâ”€â”€ ğŸ“‚ output/               # JSON output with cleaned heading outlines
â”œâ”€â”€ ğŸ“‚ models/               # Contains ONNX model and classifier artifacts
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2.onnx
â”‚   â”œâ”€â”€ tokenizer/tokenizer.json
â”‚   â”œâ”€â”€ heading_classifier.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ ğŸ§  main.py              # Main script to process PDFs
â”œâ”€â”€ ğŸ“„ logs_removed.json     # Headings removed with reasons
â””â”€â”€ ğŸ“„ logs_duplicates.json  # Duplicates skipped during processing
```

---

## ğŸ§  How It Works

1. **PDF Parsing**
   Uses `unstructured` to extract text elements from each PDF.

2. **Filtering**
   Filters out footers, very short lines, and irrelevant sections.

3. **Language Handling**
   Detects the language of each heading and translates to English using `deep-translator`.

4. **Embedding**
   Uses ONNX version of `all-MiniLM-L6-v2` for fast vector embedding.

5. **Prediction**
   Classifies headings into H1/H2/H3 via trained `LogisticRegression` model.

6. **Output**
   Produces structured JSON with heading text, page number, and level.

---

## ğŸ§ª Example Output

```json
{
  "title": "sample",
  "outline": [
    { "level": "H1", "text": "Introduction", "page": 1 },
    { "level": "H2", "text": "1.1 What is AI?", "page": 2 },
    { "level": "H3", "text": "History of AI", "page": 3 }
  ]
}
```

---

## ğŸ›  Technologies Used

* **ONNX Runtime** â€” Fast transformer inference engine
* **HuggingFace Tokenizers** â€” Tokenizing text for ONNX input
* **scikit-learn** â€” Heading level classifier
* **langdetect** â€” Detects language of headings
* **deep-translator** â€” Translates headings to English
* **unstructured** â€” Parses PDFs into structured elements
* **concurrent.futures** â€” Enables multi-threaded PDF processing

---

## âš™ï¸ Installation & Setup

### ğŸ”§ Prerequisites

Make sure you have Docker and Docker Compose installed.

### ğŸš€ Build & Run

1. **Clone the repository:**

   ```bash
    git clone git@github.com:Shashank110205/Adobe_Hack.git
    cd Adobe_Hack
   ```

2. **Build the Docker image:**

   ```bash
    docker compose build
    # or build the image manually using
    docker build -t pdf-processor .
   ```

3. **Run the Docker container:**

   ```bash
    docker run -it --rm \
      --name pdf-processor \
      --volume "<path_to_the_folder_with_the_input_pdfs>:/app/input:ro" \
      --volume "<path_to_the_output_directory>:/app/output" \
      --volume "<path_to_the_logs_directory_if_needed>:/app/logs" \ # this line is optional
      pdf-processor
   ```

---

## ğŸ§© Future Enhancements

* [ ] Include both original and translated headings in output JSON
* [ ] Add `"lang"` field to each heading for metadata
* [ ] Deploy as a web app using FastAPI or Streamlit
* [ ] Package as a command-line tool for wider usage

---

## ğŸ“Œ Why This Project is Valuable

This tool is ideal for:

* Automatic table-of-contents extraction from academic or technical PDFs
* Supporting multilingual documents (e.g., Hindi, Arabic, Chinese)
* Creating clean, structured outlines for indexing, summarization, or navigation
