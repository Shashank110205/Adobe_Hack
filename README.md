# ğŸ§¾ PDF Heading Extractor

This project extracts structured outlines from PDF documents by detecting headings and classifying them into hierarchical levels (H1, H2, H3). The solution is designed to be efficient, multilingual-aware, and ready for scaling across diverse document types.

---

## ğŸ” What This Project Does

This tool:

* Scans PDFs for structural headings like titles and section headers
* Detects the language of each heading
* Translates non-English headings into English
* Embeds the translated headings using a fast ONNX model
* Predicts their structure level using a trained machine learning classifier
* Outputs a clean, structured JSON outline for each PDF

---

## âœ… Key Features

| Feature                    | Description                                                                   |
| -------------------------- | ----------------------------------------------------------------------------- |
| ğŸŒ Multilingual Support    | Automatically detects and translates non-English headings                     |
| âš¡ Optimized Inference      | Uses ONNX and batch processing for faster embedding                           |
| ğŸ§  Accurate Classification | Predicts heading levels (H1, H2, H3) with a trained Logistic Regression model |
| ğŸ§¹ Noise Removal           | Filters out non-structural text (e.g., page numbers, footers)                 |
| ğŸ” Duplicate Detection     | Skips repeated headings to avoid clutter                                      |
| ğŸ§¾ Logging                 | Keeps logs of all removed and duplicate entries                               |
| ğŸš€ Scalable                | Supports concurrent processing of multiple PDFs                               |

---

## ğŸ“ Project Structure

```
ğŸ“¦ Project Root
â”œâ”€â”€ ğŸ“‚ input/                # Drop your PDFs here
â”œâ”€â”€ ğŸ“‚ output/               # JSON output with cleaned heading outlines
â”œâ”€â”€ ğŸ“‚ models/               # Contains ONNX model and classifier artifacts
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2.onnx
â”‚   â”œâ”€â”€ tokenizer/tokenizer.json
â”‚   â”œâ”€â”€ heading_classifier.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ ğŸ§  main.py              # Main script to process PDFs
â”œâ”€â”€ ğŸ“„ logs_removed.json     # Headings removed with reasons
â””â”€â”€ ğŸ“„ logs_duplicates.json  # Duplicates skipped during processing
```

---

## ğŸ§  How It Works

1. **PDF Parsing**
   Uses `unstructured` to extract text elements from each PDF.

2. **Filtering**
   Filters out footers, very short lines, and irrelevant sections.

3. **Language Handling**
   Detects the language of each heading and translates to English using `deep-translator`.

4. **Embedding**
   Uses ONNX version of `all-MiniLM-L6-v2` for fast vector embedding.

5. **Prediction**
   Classifies headings into H1/H2/H3 via trained `LogisticRegression` model.

6. **Output**
   Produces structured JSON with heading text, page number, and level.

---

## ğŸ§ª Example Output

```json
{
  "title": "sample",
  "outline": [
    { "level": "H1", "text": "Introduction", "page": 1 },
    { "level": "H2", "text": "1.1 What is AI?", "page": 2 },
    { "level": "H3", "text": "History of AI", "page": 3 }
  ]
}
```

---

## ğŸ›  Technologies Used

* **ONNX Runtime** â€” Fast transformer inference engine
* **HuggingFace Tokenizers** â€” Tokenizing text for ONNX input
* **scikit-learn** â€” Heading level classifier
* **langdetect** â€” Detects language of headings
* **deep-translator** â€” Translates headings to English
* **unstructured** â€” Parses PDFs into structured elements
* **concurrent.futures** â€” Enables multi-threaded PDF processing

---

## âš™ï¸ Installation & Setup

### ğŸ”§ Prerequisites

Make sure you have Docker and Docker Compose installed.

### ğŸš€ Build & Run

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/pdf-heading-extractor
   cd pdf-heading-extractor
   ```

2. **Build the Docker image:**

   ```bash
   docker compose build
   ```

3. **Start the service:**

   ```bash
   docker compose up
   ```

> ğŸ“´ Once the image is built, the application can be run completely **offline** â€” no internet is required to extract headings from PDFs.

### ğŸ”— Accessing the App

After the container is running, the API will be available at:

```
http://localhost:8000/
```

>[!TIP]
> You can interact with the API using the Swagger UI. The UI is available at:
>
>```
>http://localhost:8000/docs
>```

---

## ğŸ§© Future Enhancements

* [ ] Include both original and translated headings in output JSON
* [ ] Add `"lang"` field to each heading for metadata
* [ ] Deploy as a web app using FastAPI or Streamlit
* [ ] Package as a command-line tool for wider usage

---

## ğŸ“Œ Why This Project is Valuable

This tool is ideal for:

* Automatic table-of-contents extraction from academic or technical PDFs
* Supporting multilingual documents (e.g., Hindi, Arabic, Chinese)
* Creating clean, structured outlines for indexing, summarization, or navigation

---

## ğŸ™Œ Summary

Youâ€™ve built a multilingual, ONNX-accelerated, production-ready PDF heading extractor thatâ€™s:

* âš¡ Fast
* ğŸŒ Language-aware
* ğŸ§  Smart
* ğŸ§¹ Clean and reliable

Ready to be deployed or extended into real-world products.

---

Let me know if you'd like to include usage examples (e.g. `curl` or Python client) or a FastAPI-based UI section!

